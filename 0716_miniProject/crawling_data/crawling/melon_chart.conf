input {
 # beat에서 데이터를 받을 logstash의 port지정
  beats {
    port => 5044 
  }
}
# headerlist = ["date", "rank", "title", "artist", "album", "code", "release_date", "genre", "comment", "like"]
filter {
  mutate {
    # 실제 데이터는 "message" 필드로 오기 때문에 csv형태의 내용을 분할하여 새로운 이름으로 필드를 추가 
    split => [ "message",  "," ] 
    add_field => {
      "date" => "%{[message][0]}"
      "rank" => "%{[message][1]}"
      "title" => "%{[message][2]}"
      "artist" => "%{[message][3]}"
      "album" => "%{[message][4]}"
      "code" => "%{[message][5]}"
      "release_date" => "%{[message][6]}"
      "genre" => "%{[message][7]}"
      "comment" => "%{[message][8]}"
      "like" => "%{[message][9]}"
    }

    # 기본으로 전송되는 데이터 분석에 불필요한 필드 제거
    remove_field => ["ecs", "host", "@version", "agent", "log", "tags",  "input", "message"]
  }

  # "date" 필드를 이용하여 Elasticsearch에서 인식할 수 있는 date 타입의 형태로 필드를 추가
  date {
    match => [ "date", "yyyy-MM-dd-HH"]
    timezone => "Asia/Seoul"
    locale => "ko"
    target => "convert_date"
  }

  # date {
  #   match => [ "release_date", "yyyy.MM.dd"]
  #   timezone => "Asia/Seoul"
  #   locale => "ko"
  # }

  # Kibana에서 데이터 분석시 필요하기 때문에 숫자 타입으로 변경
  mutate {
    convert => {
      "rank" => "integer"
      "code" => "integer"
      "comment" => "integer"
      "like" => "integer"
    }
    remove_field => [ "@timestamp" ]
  }
}

output {

  # 콘솔창에 어떤 데이터들로 필터링 되었는지 확인
  stdout {
          codec => rubydebug
  }

  # 위에서 설치한 Elasticsearch 로 "covid-19" 라는 이름으로 인덱싱 
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "melon_chart"
  }
}